{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning in Python using TensorFlow and Keras\n",
    "\n",
    "In this section, we are going to explore the tensorflow package by creating a neural network to determine hand written numbers. We will be using the MNIST data set. This is example is like the \"hello world\" of deep learning. This activity should help us get familiar with deep learning and how we can apply it to our current project. This example will be using a convolutional neural network (CNN). For our project for predicting games, we will use a multilayer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get 28x28 images of handwritten digits 0-9\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) =  mnist.load_data()\n",
    "\n",
    "# Normalize our data\n",
    "X_train = tf.keras.utils.normalize(X_train)\n",
    "X_test = tf.keras.utils.normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show the first image in our training set\n",
    "plt.imshow(X_train[0], cmap = plt.cm.binary)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 986us/step - loss: 0.4754 - accuracy: 0.8623\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 2s 927us/step - loss: 0.1127 - accuracy: 0.9657\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 2s 807us/step - loss: 0.0740 - accuracy: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d79dad88e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add our input layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Add a hidden layers\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "\n",
    "# Add output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 658us/step - loss: 0.0791 - accuracy: 0.9749\n",
      "Validation loss: 0.07908321171998978\n",
      "Validation accuracy: 0.9749000072479248\n"
     ]
    }
   ],
   "source": [
    "validation_loss, validation_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Validation loss: {validation_loss}\")\n",
    "print(f\"Validation accuracy: {validation_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 28, 28) dtype=float32>,)\n",
      "Consider rewriting this model with the Functional API.\n",
      "The model's prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model.predict([X_test])\n",
    "print(f\"The model's prediction: {np.argmax(predictions[0])}\")\n",
    "\n",
    "plt.imshow(X_test[0], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Baseball Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start training a neural network using cleaned retrosheet data that we generated when we were training the random forest data. This data has the moving averages for each team over a 10 game span and contains the box score for each game played between the 2014 and 2019 seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Number of game</th>\n",
       "      <th>Visiting Team</th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Visiting Team Score</th>\n",
       "      <th>Home Team Score</th>\n",
       "      <th>Home Score SMA</th>\n",
       "      <th>Home Score CMA</th>\n",
       "      <th>Home Score EMA</th>\n",
       "      <th>Home At-bats SMA</th>\n",
       "      <th>...</th>\n",
       "      <th>Visiting Errors EMA</th>\n",
       "      <th>Visiting Passed Balls SMA</th>\n",
       "      <th>Visiting Passed Balls CMA</th>\n",
       "      <th>Visiting Passed Balls EMA</th>\n",
       "      <th>Visiting Double Plays SMA</th>\n",
       "      <th>Visiting Double Plays CMA</th>\n",
       "      <th>Visiting Double Plays EMA</th>\n",
       "      <th>Visiting Triple Plays SMA</th>\n",
       "      <th>Visiting Triple Plays CMA</th>\n",
       "      <th>Visiting Triple Plays EMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20140415</td>\n",
       "      <td>0</td>\n",
       "      <td>NYN</td>\n",
       "      <td>ARI</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.430552</td>\n",
       "      <td>34.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064909</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.813387</td>\n",
       "      <td>0.891189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20140416</td>\n",
       "      <td>0</td>\n",
       "      <td>NYN</td>\n",
       "      <td>ARI</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.454545</td>\n",
       "      <td>2.806815</td>\n",
       "      <td>34.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064777</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.811741</td>\n",
       "      <td>0.729154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20140418</td>\n",
       "      <td>0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>MIA</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>6.013663</td>\n",
       "      <td>33.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066532</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.907258</td>\n",
       "      <td>1.048140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>1.384551e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20140418</td>\n",
       "      <td>0</td>\n",
       "      <td>CHA</td>\n",
       "      <td>TEX</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>5.009391</td>\n",
       "      <td>33.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722905</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.099796</td>\n",
       "      <td>0.105171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942974</td>\n",
       "      <td>1.034505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>2.654710e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20140418</td>\n",
       "      <td>0</td>\n",
       "      <td>SFN</td>\n",
       "      <td>SDN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>2.996733</td>\n",
       "      <td>31.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437913</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.056795</td>\n",
       "      <td>0.087325</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.900609</td>\n",
       "      <td>0.715089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  Number of game Visiting Team Home Team  Visiting Team Score  \\\n",
       "0  20140415               0           NYN       ARI                    9   \n",
       "1  20140416               0           NYN       ARI                    5   \n",
       "2  20140418               0           SEA       MIA                    4   \n",
       "3  20140418               0           CHA       TEX                    0   \n",
       "4  20140418               0           SFN       SDN                    1   \n",
       "\n",
       "   Home Team Score  Home Score SMA  Home Score CMA  Home Score EMA  \\\n",
       "0                0             3.8        3.800000        3.430552   \n",
       "1                2             3.7        3.454545        2.806815   \n",
       "2                8             5.8        5.800000        6.013663   \n",
       "3               12             4.1        4.100000        5.009391   \n",
       "4                2             3.1        3.100000        2.996733   \n",
       "\n",
       "   Home At-bats SMA  ...  Visiting Errors EMA  Visiting Passed Balls SMA  \\\n",
       "0              34.6  ...             0.140383                        0.0   \n",
       "1              34.3  ...             0.114859                        0.0   \n",
       "2              33.5  ...             0.660538                        0.0   \n",
       "3              33.7  ...             0.722905                        0.1   \n",
       "4              31.4  ...             0.437913                        0.1   \n",
       "\n",
       "   Visiting Passed Balls CMA  Visiting Passed Balls EMA  \\\n",
       "0                   0.064909                   0.008247   \n",
       "1                   0.064777                   0.006748   \n",
       "2                   0.066532                   0.000986   \n",
       "3                   0.099796                   0.105171   \n",
       "4                   0.056795                   0.087325   \n",
       "\n",
       "   Visiting Double Plays SMA  Visiting Double Plays CMA  \\\n",
       "0                        0.7                   0.813387   \n",
       "1                        0.7                   0.811741   \n",
       "2                        1.1                   0.907258   \n",
       "3                        1.0                   0.942974   \n",
       "4                        1.1                   0.900609   \n",
       "\n",
       "   Visiting Double Plays EMA  Visiting Triple Plays SMA  \\\n",
       "0                   0.891189                        0.0   \n",
       "1                   0.729154                        0.0   \n",
       "2                   1.048140                        0.0   \n",
       "3                   1.034505                        0.0   \n",
       "4                   0.715089                        0.0   \n",
       "\n",
       "   Visiting Triple Plays CMA  Visiting Triple Plays EMA  \n",
       "0                   0.000000               0.000000e+00  \n",
       "1                   0.000000               0.000000e+00  \n",
       "2                   0.004032               1.384551e-15  \n",
       "3                   0.006110               2.654710e-26  \n",
       "4                   0.000000               0.000000e+00  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"./datasets/cleaned_data/clean_retrosheet.csv\")\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We loaded the data from our previously generated csv. Now let's make a \"Target\" column in our dataset which reflect which team won the game. This will therefore be a binary classification problem since there are onely two outcomes: Home Team Won, Visiting Team Won. We will represent these outcomes as a 0 and 1 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8565 training examples\n",
      "There are 2142 validation examples\n",
      "There are 3570 test examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home Score EMA</th>\n",
       "      <th>Home At-bats EMA</th>\n",
       "      <th>Home Hits EMA</th>\n",
       "      <th>Home Doubles EMA</th>\n",
       "      <th>Home Triples EMA</th>\n",
       "      <th>Home Homeruns EMA</th>\n",
       "      <th>Home RBIs EMA</th>\n",
       "      <th>Home Sacrifice Hits EMA</th>\n",
       "      <th>Home Sacrifice Flies EMA</th>\n",
       "      <th>Home Hit-by-pitch EMA</th>\n",
       "      <th>...</th>\n",
       "      <th>Visiting Pitchers Used EMA</th>\n",
       "      <th>Visiting Individual Earned Runs EMA</th>\n",
       "      <th>Visiting Earned Runs EMA</th>\n",
       "      <th>Visiting Putouts EMA</th>\n",
       "      <th>Visiting Assists EMA</th>\n",
       "      <th>Visiting Errors EMA</th>\n",
       "      <th>Visiting Double Plays EMA</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Visiting Team Runs over Earned Runs EMA</th>\n",
       "      <th>Home Team Runs over Earned Runs EMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5393</th>\n",
       "      <td>3.129417</td>\n",
       "      <td>34.300112</td>\n",
       "      <td>7.978190</td>\n",
       "      <td>1.883733</td>\n",
       "      <td>0.166987</td>\n",
       "      <td>0.617061</td>\n",
       "      <td>2.751294</td>\n",
       "      <td>0.170593</td>\n",
       "      <td>0.354347</td>\n",
       "      <td>0.136779</td>\n",
       "      <td>...</td>\n",
       "      <td>3.866208</td>\n",
       "      <td>3.135750</td>\n",
       "      <td>3.135750</td>\n",
       "      <td>26.016729</td>\n",
       "      <td>9.527653</td>\n",
       "      <td>0.474326</td>\n",
       "      <td>0.683740</td>\n",
       "      <td>0</td>\n",
       "      <td>1.387312</td>\n",
       "      <td>0.681736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>4.057572</td>\n",
       "      <td>31.567578</td>\n",
       "      <td>7.226751</td>\n",
       "      <td>1.246953</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>1.302334</td>\n",
       "      <td>3.879783</td>\n",
       "      <td>0.032616</td>\n",
       "      <td>0.221340</td>\n",
       "      <td>0.390433</td>\n",
       "      <td>...</td>\n",
       "      <td>3.767579</td>\n",
       "      <td>4.453522</td>\n",
       "      <td>4.453522</td>\n",
       "      <td>27.107553</td>\n",
       "      <td>9.680803</td>\n",
       "      <td>0.565999</td>\n",
       "      <td>0.462446</td>\n",
       "      <td>1</td>\n",
       "      <td>1.331681</td>\n",
       "      <td>1.310020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10270</th>\n",
       "      <td>6.339452</td>\n",
       "      <td>36.225535</td>\n",
       "      <td>11.358290</td>\n",
       "      <td>2.105348</td>\n",
       "      <td>0.783111</td>\n",
       "      <td>1.251797</td>\n",
       "      <td>6.164332</td>\n",
       "      <td>0.557224</td>\n",
       "      <td>0.349859</td>\n",
       "      <td>0.353334</td>\n",
       "      <td>...</td>\n",
       "      <td>4.944840</td>\n",
       "      <td>3.725906</td>\n",
       "      <td>3.725906</td>\n",
       "      <td>26.299086</td>\n",
       "      <td>8.764597</td>\n",
       "      <td>0.322780</td>\n",
       "      <td>0.516379</td>\n",
       "      <td>1</td>\n",
       "      <td>1.599789</td>\n",
       "      <td>1.029427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12244</th>\n",
       "      <td>2.682707</td>\n",
       "      <td>33.227132</td>\n",
       "      <td>6.038032</td>\n",
       "      <td>1.588323</td>\n",
       "      <td>0.235041</td>\n",
       "      <td>0.382817</td>\n",
       "      <td>2.577523</td>\n",
       "      <td>0.214274</td>\n",
       "      <td>0.752044</td>\n",
       "      <td>0.245387</td>\n",
       "      <td>...</td>\n",
       "      <td>4.623817</td>\n",
       "      <td>4.982261</td>\n",
       "      <td>4.982261</td>\n",
       "      <td>27.153530</td>\n",
       "      <td>8.346317</td>\n",
       "      <td>0.847711</td>\n",
       "      <td>1.091874</td>\n",
       "      <td>1</td>\n",
       "      <td>1.223765</td>\n",
       "      <td>0.689434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5516</th>\n",
       "      <td>6.507842</td>\n",
       "      <td>33.706557</td>\n",
       "      <td>10.781671</td>\n",
       "      <td>1.689922</td>\n",
       "      <td>0.278767</td>\n",
       "      <td>1.119104</td>\n",
       "      <td>6.400722</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.659045</td>\n",
       "      <td>0.100298</td>\n",
       "      <td>...</td>\n",
       "      <td>3.615473</td>\n",
       "      <td>4.999111</td>\n",
       "      <td>4.998749</td>\n",
       "      <td>26.949943</td>\n",
       "      <td>11.853054</td>\n",
       "      <td>0.685029</td>\n",
       "      <td>1.419451</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973559</td>\n",
       "      <td>1.887709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Home Score EMA  Home At-bats EMA  Home Hits EMA  Home Doubles EMA  \\\n",
       "5393         3.129417         34.300112       7.978190          1.883733   \n",
       "1317         4.057572         31.567578       7.226751          1.246953   \n",
       "10270        6.339452         36.225535      11.358290          2.105348   \n",
       "12244        2.682707         33.227132       6.038032          1.588323   \n",
       "5516         6.507842         33.706557      10.781671          1.689922   \n",
       "\n",
       "       Home Triples EMA  Home Homeruns EMA  Home RBIs EMA  \\\n",
       "5393           0.166987           0.617061       2.751294   \n",
       "1317           0.000066           1.302334       3.879783   \n",
       "10270          0.783111           1.251797       6.164332   \n",
       "12244          0.235041           0.382817       2.577523   \n",
       "5516           0.278767           1.119104       6.400722   \n",
       "\n",
       "       Home Sacrifice Hits EMA  Home Sacrifice Flies EMA  \\\n",
       "5393                  0.170593                  0.354347   \n",
       "1317                  0.032616                  0.221340   \n",
       "10270                 0.557224                  0.349859   \n",
       "12244                 0.214274                  0.752044   \n",
       "5516                  0.006912                  0.659045   \n",
       "\n",
       "       Home Hit-by-pitch EMA  ...  Visiting Pitchers Used EMA  \\\n",
       "5393                0.136779  ...                    3.866208   \n",
       "1317                0.390433  ...                    3.767579   \n",
       "10270               0.353334  ...                    4.944840   \n",
       "12244               0.245387  ...                    4.623817   \n",
       "5516                0.100298  ...                    3.615473   \n",
       "\n",
       "       Visiting Individual Earned Runs EMA  Visiting Earned Runs EMA  \\\n",
       "5393                              3.135750                  3.135750   \n",
       "1317                              4.453522                  4.453522   \n",
       "10270                             3.725906                  3.725906   \n",
       "12244                             4.982261                  4.982261   \n",
       "5516                              4.999111                  4.998749   \n",
       "\n",
       "       Visiting Putouts EMA  Visiting Assists EMA  Visiting Errors EMA  \\\n",
       "5393              26.016729              9.527653             0.474326   \n",
       "1317              27.107553              9.680803             0.565999   \n",
       "10270             26.299086              8.764597             0.322780   \n",
       "12244             27.153530              8.346317             0.847711   \n",
       "5516              26.949943             11.853054             0.685029   \n",
       "\n",
       "       Visiting Double Plays EMA  Winner  \\\n",
       "5393                    0.683740       0   \n",
       "1317                    0.462446       1   \n",
       "10270                   0.516379       1   \n",
       "12244                   1.091874       1   \n",
       "5516                    1.419451       1   \n",
       "\n",
       "       Visiting Team Runs over Earned Runs EMA  \\\n",
       "5393                                  1.387312   \n",
       "1317                                  1.331681   \n",
       "10270                                 1.599789   \n",
       "12244                                 1.223765   \n",
       "5516                                  0.973559   \n",
       "\n",
       "       Home Team Runs over Earned Runs EMA  \n",
       "5393                              0.681736  \n",
       "1317                              1.310020  \n",
       "10270                             1.029427  \n",
       "12244                             0.689434  \n",
       "5516                              1.887709  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataframe.copy()\n",
    "\n",
    "# Create a column indicating which team won\n",
    "data[\"Winner\"] = np.where(data[\"Visiting Team Score\"] < data[\"Home Team Score\"], 0, 1)\n",
    "\n",
    "# Add two more columns: runs EMA / earned runs EMA for both teams\n",
    "data[\"Visiting Team Runs over Earned Runs EMA\"] = data[\"Visiting Score EMA\"] / data[\"Visiting Earned Runs EMA\"]\n",
    "data[\"Home Team Runs over Earned Runs EMA\"] = data[\"Home Score EMA\"] / data[\"Home Earned Runs EMA\"]\n",
    "\n",
    "# Drop features and un-used columns that we know won't be useful\n",
    "data.drop(data.filter(regex=\"Triple Plays\").columns, axis=1, inplace=True)\n",
    "data.drop(data.filter(regex=\"Wild Pitches\").columns, axis=1, inplace=True)\n",
    "data.drop(data.filter(regex=\"Balks\").columns, axis=1, inplace=True)\n",
    "data.drop(data.filter(regex=\"Passed Balls\").columns, axis=1, inplace=True)\n",
    "data.drop(data.filter(regex=\"CMA\").columns, axis=1, inplace=True)\n",
    "data.drop(data.filter(regex=\"SMA\").columns, axis=1, inplace=True)\n",
    "data.drop(columns=[\"Date\",\n",
    "                   \"Number of game\",\n",
    "                   \"Visiting Team\",\n",
    "                   \"Home Team\",\n",
    "                   \"Visiting Team Score\",\n",
    "                   \"Home Team Score\"],\n",
    "          inplace=True)\n",
    "\n",
    "# Split the data into training sets and test sets\n",
    "train, test = train_test_split(data, test_size=0.25)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "\n",
    "assert train.shape[1] == test.shape[1]\n",
    "\n",
    "print(f\"There are {len(train)} training examples\")\n",
    "print(f\"There are {len(val)} validation examples\")\n",
    "print(f\"There are {len(test)} test examples\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data Ready for Tensorflow\n",
    "Now we have our training set and our test set. Before we can train a model, we must first get the dataframe objects properly ready and also correctly identify the feature columns we will be using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to wrap the dataframes with `tf.data`, in order to shuffle and batch the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('Winner')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created the input pipeline. Let's call it to see the format of the data it returns. For demonstration purposes, we will enter a small batch size to keep the output readable and also only show the first three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['Home Score EMA', 'Home At-bats EMA', 'Home Hits EMA']\n",
      "A batch of Home Hits EMA: tf.Tensor([3.60397749 3.27112787 3.95243266 3.41187279 4.42485556], shape=(5,), dtype=float64)\n",
      "A batch of targets: tf.Tensor([1 0 0 0 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "train_ds = df_to_dataset(train, batch_size=5)\n",
    "\n",
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys())[:3])\n",
    "print('A batch of Home Hits EMA:', train_features[\"Home Score EMA\"])\n",
    "print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, all of our features are Numeric. For each Numeric feature, we will have to use a `Normalization()` layer to make sure that the mean of each feature is a 0 and its standard deviation is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a Normalization Layer\n",
    "def get_normalization_layer(name, dataset):\n",
    "    # Create a Normalization layer for our feature.\n",
    "    normalizer = preprocessing.Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[-1.6751691 ],\n",
       "       [-0.74389887],\n",
       "       [ 0.36771962],\n",
       "       [-1.9614308 ],\n",
       "       [ 1.0176914 ]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_hits_col = train_features[\"Home Hits EMA\"]\n",
    "layer = get_normalization_layer(\"Home Hits EMA\", train_ds)\n",
    "layer(home_hits_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Keras-functional API to build the model since it is more flexible than the tf.keras.Sequential API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 50/50 [00:13<00:00,  3.84feature/s]\n"
     ]
    }
   ],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "for header in tqdm(list(train_features.keys()), unit=\"feature\"):\n",
    "    numeric_column = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_column = normalization_layer(numeric_column)\n",
    "    all_inputs.append(numeric_column)\n",
    "    encoded_features.append(encoded_numeric_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(all_inputs, output)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "134/134 [==============================] - 3s 8ms/step - loss: 0.7226 - accuracy: 0.5309 - val_loss: 0.6912 - val_accuracy: 0.5271\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.5396 - val_loss: 0.6902 - val_accuracy: 0.5261\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5461 - val_loss: 0.6899 - val_accuracy: 0.5271\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5534 - val_loss: 0.6896 - val_accuracy: 0.5261\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 1s 3ms/step - loss: 0.6773 - accuracy: 0.5516 - val_loss: 0.6907 - val_accuracy: 0.5257\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.5395 - val_loss: 0.6905 - val_accuracy: 0.5271\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.6669 - accuracy: 0.5631 - val_loss: 0.6927 - val_accuracy: 0.5303\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.5595 - val_loss: 0.6911 - val_accuracy: 0.5271\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.5793 - val_loss: 0.6939 - val_accuracy: 0.5341\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.5754 - val_loss: 0.6965 - val_accuracy: 0.5364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d804183d30>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.5252\n",
      "Accuracy 0.5252100825309753\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dict = test.to_dict(\"list\")\n",
    "# print(test.iloc[2])\n",
    "\n",
    "# input_dict = {name: tf.convert_to_tensor([value[2]]) for name, value in test_dict.items()}\n",
    "# predictions = model.predict(input_dict)\n",
    "# prob = tf.nn.sigmoid(predictions[0])\n",
    "# print(float(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment of the Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the neural network did not do much better than the SVM model or the Random Forrest Classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
